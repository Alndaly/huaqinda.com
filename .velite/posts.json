[
  {
    "title": "基于certbot自动生成ssh证书",
    "slug": "posts/certbot",
    "lastModified": "2025-05-15T15:20:27.000Z",
    "metadata": {
      "readingTime": 1,
      "wordCount": 79.68
    },
    "excerpt": "基于 Nginx 方式最为方便\n1. 安装 Certbot\nubuntu\nsudo apt update\nsudo apt install certbot python3-certbot-nginx  # 如果用Nginx\nsudo apt install certbot python3-certbot-apache  # 如果用Apache\n\nmacos\nbrew install certbot\n\n2. 获取 SSL 证书\nsudo certbot --nginx\n\n这个脚本可以一键配置\n你只需要跟着提示走一遍就",
    "content": "<p>基于 Nginx 方式最为方便</p>\n<h2><strong>1. 安装 Certbot</strong></h2>\n<p>ubuntu</p>\n<pre><code class=\"language-bash\">sudo apt update\nsudo apt install certbot python3-certbot-nginx  # 如果用Nginx\nsudo apt install certbot python3-certbot-apache  # 如果用Apache\n</code></pre>\n<p>macos</p>\n<pre><code class=\"language-bash\">brew install certbot\n</code></pre>\n<h2>2. 获取 SSL 证书</h2>\n<pre><code class=\"language-bash\">sudo certbot --nginx\n</code></pre>\n<p>这个脚本可以一键配置</p>\n<p>你只需要跟着提示走一遍就好</p>\n<h2>3.自动续期</h2>\n<p>默认 certbot 会开启一个定时服务进行自动续期，不需要你再配置了</p>\n<p>手动续期命令</p>\n<pre><code class=\"language-bash\">sudo certbot renew --dry-run\n</code></pre>",
    "code": "const{Fragment:n,jsx:e,jsxs:r}=arguments[0];function _createMdxContent(t){const c={code:\"code\",h2:\"h2\",p:\"p\",pre:\"pre\",strong:\"strong\",...t.components};return r(n,{children:[e(c.p,{children:\"基于 Nginx 方式最为方便\"}),\"\\n\",e(c.h2,{children:e(c.strong,{children:\"1. 安装 Certbot\"})}),\"\\n\",e(c.p,{children:\"ubuntu\"}),\"\\n\",e(c.pre,{children:e(c.code,{className:\"language-bash\",children:\"sudo apt update\\nsudo apt install certbot python3-certbot-nginx  # 如果用Nginx\\nsudo apt install certbot python3-certbot-apache  # 如果用Apache\\n\"})}),\"\\n\",e(c.p,{children:\"macos\"}),\"\\n\",e(c.pre,{children:e(c.code,{className:\"language-bash\",children:\"brew install certbot\\n\"})}),\"\\n\",e(c.h2,{children:\"2. 获取 SSL 证书\"}),\"\\n\",e(c.pre,{children:e(c.code,{className:\"language-bash\",children:\"sudo certbot --nginx\\n\"})}),\"\\n\",e(c.p,{children:\"这个脚本可以一键配置\"}),\"\\n\",e(c.p,{children:\"你只需要跟着提示走一遍就好\"}),\"\\n\",e(c.h2,{children:\"3.自动续期\"}),\"\\n\",e(c.p,{children:\"默认 certbot 会开启一个定时服务进行自动续期，不需要你再配置了\"}),\"\\n\",e(c.p,{children:\"手动续期命令\"}),\"\\n\",e(c.pre,{children:e(c.code,{className:\"language-bash\",children:\"sudo certbot renew --dry-run\\n\"})})]})}return{default:function(n={}){const{wrapper:r}=n.components||{};return r?e(r,{...n,children:e(_createMdxContent,{...n})}):_createMdxContent(n)}};",
    "permalink": "/posts/certbot"
  },
  {
    "title": "ComfyUI 小技巧",
    "slug": "posts/comfyui-tips",
    "lastModified": "2025-05-15T15:20:27.000Z",
    "metadata": {
      "readingTime": 2,
      "wordCount": 598.1600000000001
    },
    "excerpt": "InstantID 使用\n如果使用 instantID 的话，关于人脸的位置，需要传入一张照片给 Apply InstantID Advanced 的 image_pks 输入参数作为位置参考。\n\n尤其注意人脸位置参考图片的尺寸需要尽量和你的浅空间大小一致，不然会出现位置和参考图不符的现象。\n\n\n截止2024/7/7，instantID仍不支持sd1.5。如果你使用1.5的模型，会报错如下\n'NoneType' object has no attribute 'shape'\n\n\nLayer Diffuse\n在 Co",
    "content": "<h2>InstantID 使用</h2>\n<p>如果使用 instantID 的话，关于人脸的位置，需要传入一张照片给 <code>Apply InstantID Advanced</code> 的 <code>image_pks</code> 输入参数作为位置参考。</p>\n<callout>\n尤其注意人脸位置参考图片的尺寸需要尽量和你的浅空间大小一致，不然会出现位置和参考图不符的现象。\n</callout>\n<callout>\n截止2024/7/7，instantID仍不支持sd1.5。如果你使用1.5的模型，会报错如下\n<pre><code class=\"language-python\">'NoneType' object has no attribute 'shape'\n</code></pre>\n</callout>\n<h2>Layer Diffuse</h2>\n<p>在 ComfyUI 中的，对应的这个实现有部分代码是有问题的，需要做修改。</p>\n<p>具体实现仓库：<a href=\"https://github.com/huchenlei/ComfyUI-layerdiffuse\">https://github.com/huchenlei/ComfyUI-layerdiffuse</a></p>\n<p>找到这个仓库目录下的文件  <code>lib_layerdiffusion/models.py</code></p>\n<p>针对其中的：</p>\n<pre><code class=\"language-python\">median = torch.median(result, dim=0).values\n</code></pre>\n<p>作出如下修改：</p>\n<pre><code class=\"language-python\">if self.load_device == torch.device(\"mps\"):\n    '''\n    In case that apple silicon devices would crash when calling torch.median() on tensors\n    in gpu vram with dimensions higher than 4, we move it to cpu, call torch.median()\n    and then move the result back to gpu.\n    '''\n    median = torch.median(result.cpu(), dim=0).values\n    median = median.to(device=self.load_device, dtype=self.dtype)\nelse:\n    median = torch.median(result, dim=0).values\n</code></pre>\n<p>保存，然后重启 ComfyUI</p>\n<p>本质原因是 apple 芯片的 gpu 在 <code>torch.median</code> 操作大于 4 个维度的向量的时候，会报错。</p>\n<p>错误简单复现：</p>\n<pre><code class=\"language-python\">import torch\na = torch.randn(8, 1, 4, 512, 512)\nmps_device = torch.device(\"mps\")\nb = a.to(mps_device)\ntt = torch.median(b, dim=0) # crash here\n</code></pre>\n<h2>MacOS14.4 中 <code>torchvision</code> 的适配问题</h2>\n<p>macos14.4 以及更新的版本中，ComfyUI 绘画会出现出图灰黑/蓝黑/模糊的情况，是 pytorch 的适配问题，详见<a href=\"https://github.com/comfyanonymous/ComfyUI/issues/2992%E3%80%82%E5%BD%93%E5%89%8D%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%A6%82%E4%B8%8B%EF%BC%9A\">https://github.com/comfyanonymous/ComfyUI/issues/2992。当前解决方法如下：</a></p>\n<pre><code class=\"language-bash\">pip install torch==2.1.2 torchvision==0.16.2\n</code></pre>\n<p>下列的版本依然会出现问题</p>\n<pre><code class=\"language-bash\">pip install torch==2.2.0 torchvision==0.17.0\npip install torch==2.2.1 torchvision==0.17.1\npip install torch torchvision # same as above\npip install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cpu # development version\n</code></pre>\n<h2>Inpainting Model 技巧</h2>\n<h4>1. 如果你没有某个 model 对应的 inpainting model，你可以通过如下方式解决</h4>\n<p>分别加载有 inpainting model 的 base model 和其 inpainting model，然后通过 modelmerge substract 节点获取 inpainting 部分，然后加载你没有 inpainting model 的那个 model，再把 modelmerge substract 节点的导出和这个 model 通过 modelmerge add 的节点合并，这样就生成了你这个 model 对应的 inpainting model。</p>\n<p><img src=\"https://qingyon-revornix-public.oss-cn-beijing.aliyuncs.com/images/202505152318494.png\" alt=\"\"></p>\n<h4>2. 如果你 inpainting 的部分的边缘过于尖锐锋利，你可以使用 differential model 节点转接 model。然后把 inpainting 部分的 mask 通过 GrowMask 节点外扩一些。</h4>\n<p><img src=\"https://qingyon-revornix-public.oss-cn-beijing.aliyuncs.com/images/202505152318077.png\" alt=\"\"></p>\n<h2>Ipadapter 应用</h2>\n<h4>mad scientist 节点</h4>\n<p>劫持了 unet 的部分 cross_attention 层，共计 12 层，其中第 4 层表示结构，第 7 层表示风格。可以通过 layer_weights 参数修改对应层数权重。</p>\n<p><img src=\"https://qingyon-revornix-public.oss-cn-beijing.aliyuncs.com/images/202505152319809.png\" alt=\"\"></p>\n<p>如果所有层权重都是 1 且 weight_type 是 linear，那么就等于一个普通的 ipadapter 应用，即生成的图片完全参考 ipadapter。</p>\n<p>如果只有 index6 设置为 1，其他保持 0，那么就等于 ipadapter 的 weight_type 取值 style_transfer，即按照你的 promt 生成图片，但是获取参考图的风格，此时如果修改其他 index 的权重到>0，可以获取到一定的参考图的元素加入到生成的图片中。</p>\n<p>在实际操作中，如果把图片同时传递到 image 和 image_negative，同时 weight_type 选取 style transfer precise，mad scientist 会把 negative 部分的结构特征乘以你设置的 index3 的权重（注意是 negative，所以是负值，也就是最终会进一步去除参考图中的结构特征），把 image 部分的风格特征乘以你设置的 index6 的权重，也就是最终会放大参考图中的风格特征。即最终结果：按比例保留风格，按比例去除结构特征。</p>\n<p><img src=\"https://qingyon-revornix-public.oss-cn-beijing.aliyuncs.com/images/202505152319526.png\" alt=\"\"></p>",
    "code": "const{Fragment:n,jsx:e,jsxs:i}=arguments[0];function _createMdxContent(t){const c={a:\"a\",code:\"code\",h2:\"h2\",h4:\"h4\",img:\"img\",p:\"p\",pre:\"pre\",...t.components},{Callout:r}=c;return r||function(n,e){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+n+\"` to be defined: you likely forgot to import, pass, or provide it.\")}(\"Callout\",!0),i(n,{children:[e(c.h2,{children:\"InstantID 使用\"}),\"\\n\",i(c.p,{children:[\"如果使用 instantID 的话，关于人脸的位置，需要传入一张照片给 \",e(c.code,{children:\"Apply InstantID Advanced\"}),\" 的 \",e(c.code,{children:\"image_pks\"}),\" 输入参数作为位置参考。\"]}),\"\\n\",e(r,{children:e(c.p,{children:\"尤其注意人脸位置参考图片的尺寸需要尽量和你的浅空间大小一致，不然会出现位置和参考图不符的现象。\"})}),\"\\n\",i(r,{children:[e(c.p,{children:\"截止2024/7/7，instantID仍不支持sd1.5。如果你使用1.5的模型，会报错如下\"}),e(c.pre,{children:e(c.code,{className:\"language-python\",children:\"'NoneType' object has no attribute 'shape'\\n\"})})]}),\"\\n\",e(c.h2,{children:\"Layer Diffuse\"}),\"\\n\",e(c.p,{children:\"在 ComfyUI 中的，对应的这个实现有部分代码是有问题的，需要做修改。\"}),\"\\n\",i(c.p,{children:[\"具体实现仓库：\",e(c.a,{href:\"https://github.com/huchenlei/ComfyUI-layerdiffuse\",children:\"https://github.com/huchenlei/ComfyUI-layerdiffuse\"})]}),\"\\n\",i(c.p,{children:[\"找到这个仓库目录下的文件  \",e(c.code,{children:\"lib_layerdiffusion/models.py\"})]}),\"\\n\",e(c.p,{children:\"针对其中的：\"}),\"\\n\",e(c.pre,{children:e(c.code,{className:\"language-python\",children:\"median = torch.median(result, dim=0).values\\n\"})}),\"\\n\",e(c.p,{children:\"作出如下修改：\"}),\"\\n\",e(c.pre,{children:e(c.code,{className:\"language-python\",children:\"if self.load_device == torch.device(\\\"mps\\\"):\\n    '''\\n    In case that apple silicon devices would crash when calling torch.median() on tensors\\n    in gpu vram with dimensions higher than 4, we move it to cpu, call torch.median()\\n    and then move the result back to gpu.\\n    '''\\n    median = torch.median(result.cpu(), dim=0).values\\n    median = median.to(device=self.load_device, dtype=self.dtype)\\nelse:\\n    median = torch.median(result, dim=0).values\\n\"})}),\"\\n\",e(c.p,{children:\"保存，然后重启 ComfyUI\"}),\"\\n\",i(c.p,{children:[\"本质原因是 apple 芯片的 gpu 在 \",e(c.code,{children:\"torch.median\"}),\" 操作大于 4 个维度的向量的时候，会报错。\"]}),\"\\n\",e(c.p,{children:\"错误简单复现：\"}),\"\\n\",e(c.pre,{children:e(c.code,{className:\"language-python\",children:'import torch\\na = torch.randn(8, 1, 4, 512, 512)\\nmps_device = torch.device(\"mps\")\\nb = a.to(mps_device)\\ntt = torch.median(b, dim=0) # crash here\\n'})}),\"\\n\",i(c.h2,{children:[\"MacOS14.4 中 \",e(c.code,{children:\"torchvision\"}),\" 的适配问题\"]}),\"\\n\",i(c.p,{children:[\"macos14.4 以及更新的版本中，ComfyUI 绘画会出现出图灰黑/蓝黑/模糊的情况，是 pytorch 的适配问题，详见\",e(c.a,{href:\"https://github.com/comfyanonymous/ComfyUI/issues/2992%E3%80%82%E5%BD%93%E5%89%8D%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%A6%82%E4%B8%8B%EF%BC%9A\",children:\"https://github.com/comfyanonymous/ComfyUI/issues/2992。当前解决方法如下：\"})]}),\"\\n\",e(c.pre,{children:e(c.code,{className:\"language-bash\",children:\"pip install torch==2.1.2 torchvision==0.16.2\\n\"})}),\"\\n\",e(c.p,{children:\"下列的版本依然会出现问题\"}),\"\\n\",e(c.pre,{children:e(c.code,{className:\"language-bash\",children:\"pip install torch==2.2.0 torchvision==0.17.0\\npip install torch==2.2.1 torchvision==0.17.1\\npip install torch torchvision # same as above\\npip install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cpu # development version\\n\"})}),\"\\n\",e(c.h2,{children:\"Inpainting Model 技巧\"}),\"\\n\",e(c.h4,{children:\"1. 如果你没有某个 model 对应的 inpainting model，你可以通过如下方式解决\"}),\"\\n\",e(c.p,{children:\"分别加载有 inpainting model 的 base model 和其 inpainting model，然后通过 modelmerge substract 节点获取 inpainting 部分，然后加载你没有 inpainting model 的那个 model，再把 modelmerge substract 节点的导出和这个 model 通过 modelmerge add 的节点合并，这样就生成了你这个 model 对应的 inpainting model。\"}),\"\\n\",e(c.p,{children:e(c.img,{src:\"https://qingyon-revornix-public.oss-cn-beijing.aliyuncs.com/images/202505152318494.png\",alt:\"\"})}),\"\\n\",e(c.h4,{children:\"2. 如果你 inpainting 的部分的边缘过于尖锐锋利，你可以使用 differential model 节点转接 model。然后把 inpainting 部分的 mask 通过 GrowMask 节点外扩一些。\"}),\"\\n\",e(c.p,{children:e(c.img,{src:\"https://qingyon-revornix-public.oss-cn-beijing.aliyuncs.com/images/202505152318077.png\",alt:\"\"})}),\"\\n\",e(c.h2,{children:\"Ipadapter 应用\"}),\"\\n\",e(c.h4,{children:\"mad scientist 节点\"}),\"\\n\",e(c.p,{children:\"劫持了 unet 的部分 cross_attention 层，共计 12 层，其中第 4 层表示结构，第 7 层表示风格。可以通过 layer_weights 参数修改对应层数权重。\"}),\"\\n\",e(c.p,{children:e(c.img,{src:\"https://qingyon-revornix-public.oss-cn-beijing.aliyuncs.com/images/202505152319809.png\",alt:\"\"})}),\"\\n\",e(c.p,{children:\"如果所有层权重都是 1 且 weight_type 是 linear，那么就等于一个普通的 ipadapter 应用，即生成的图片完全参考 ipadapter。\"}),\"\\n\",e(c.p,{children:\"如果只有 index6 设置为 1，其他保持 0，那么就等于 ipadapter 的 weight_type 取值 style_transfer，即按照你的 promt 生成图片，但是获取参考图的风格，此时如果修改其他 index 的权重到>0，可以获取到一定的参考图的元素加入到生成的图片中。\"}),\"\\n\",e(c.p,{children:\"在实际操作中，如果把图片同时传递到 image 和 image_negative，同时 weight_type 选取 style transfer precise，mad scientist 会把 negative 部分的结构特征乘以你设置的 index3 的权重（注意是 negative，所以是负值，也就是最终会进一步去除参考图中的结构特征），把 image 部分的风格特征乘以你设置的 index6 的权重，也就是最终会放大参考图中的风格特征。即最终结果：按比例保留风格，按比例去除结构特征。\"}),\"\\n\",e(c.p,{children:e(c.img,{src:\"https://qingyon-revornix-public.oss-cn-beijing.aliyuncs.com/images/202505152319526.png\",alt:\"\"})})]})}return{default:function(n={}){const{wrapper:i}=n.components||{};return i?e(i,{...n,children:e(_createMdxContent,{...n})}):_createMdxContent(n)}};",
    "permalink": "/posts/comfyui-tips"
  },
  {
    "title": "lora 模型训练",
    "slug": "posts/lora",
    "lastModified": "2025-05-07T16:14:25.000Z",
    "metadata": {
      "readingTime": 6,
      "wordCount": 1551.8000000000002
    },
    "excerpt": "注意，本文档只针对 m 系列芯片的 macbook 用户。\n快速开始\n下载 kohya 仓库\ngit clone git@github.com:bmaltais/kohya_ss.git\n\n启动 kohya\ncd kohya_ss./gui.sh\n\n图像裁剪\nwebui 自带裁剪功能，具体如下\n\nwebui 默认的人像焦点裁剪有时候并不是那么可靠，需要在完成之后检查一遍。如果人物比较瘦长的情况下的的话还可能导致人物被裁剪，这种情况建议手动裁切或者扩充边沿。\n💡 裁剪结果也不一定要选择 512*512，因为 sd ",
    "content": "<p>注意，本文档只针对 m 系列芯片的 macbook 用户。</p>\n<h2><strong>快速开始</strong></h2>\n<h3><strong>下载 kohya 仓库</strong></h3>\n<pre><code class=\"language-bash\">git clone git@github.com:bmaltais/kohya_ss.git\n</code></pre>\n<h3><strong>启动 kohya</strong></h3>\n<pre><code class=\"language-bash\">cd kohya_ss./gui.sh\n</code></pre>\n<h3><strong>图像裁剪</strong></h3>\n<p>webui 自带裁剪功能，具体如下</p>\n<p><img src=\"https://oss.kinda.info/image/202403060009884.png\" alt=\"\"></p>\n<p>webui 默认的人像焦点裁剪有时候并不是那么可靠，需要在完成之后检查一遍。如果人物比较瘦长的情况下的的话还可能导致人物被裁剪，这种情况建议手动裁切或者扩充边沿。</p>\n<p>💡 裁剪结果也不一定要选择 512*512，因为 sd 在训练的时候会预先根据不同图片大小进行分桶。</p>\n<h3><strong>打标</strong></h3>\n<p>下面这个仓库是公认的比较合适的打标仓库（似乎对于二次元风格更合适一些，应该是因为都是基于标签制的，并且标签来自于<a href=\"https://safebooru.org/\">https://safebooru.org</a>这一网站经训练生成的）。</p>\n<p><a href=\"https://github.com/picobyte/stable-diffusion-webui-wd14-tagger\">https://github.com/picobyte/stable-diffusion-webui-wd14-tagger</a></p>\n<p>把项目克隆到 sd 的 extensions 目录下，然后重启 sd 即可。</p>\n<pre><code class=\"language-bash\">cd ./extensionsgit clone git@github.com:picobyte/stable-diffusion-webui-wd14-tagger.git\n</code></pre>\n<p><img src=\"https://oss.kinda.info/image/202403061424310.png\" alt=\"\"></p>\n<p>注意下面的 Additional tags，这里你需要填入这个 lora 的触发词语，在最终打标完成的 txt 文件中这个触发词语会被加入并且置于 prompts 的第一个。</p>\n<h3><strong>设置训练参数</strong></h3>\n<p>详见<a href=\"https://human-ai.site/image/lora#%E5%8F%82%E6%95%B0%E9%80%89%E6%8B%A9\">参数选择</a></p>\n<h3><strong>选底模</strong></h3>\n<p>详见<a href=\"https://human-ai.site/image/lora#%E5%8F%82%E6%95%B0%E9%80%89%E6%8B%A9\">参数选择</a></p>\n<h3><strong>建立训练文件夹（注意：文件夹的相关路径不要有中文和空格）</strong></h3>\n<ol>\n<li>\n<p>建立一个文件夹，命名为你的训练项目名字。比如 NingGuang。</p>\n</li>\n<li>\n<p>在 NingGuang 目录下新建三个文件夹，分别命名为 image、log、models。</p>\n</li>\n<li>\n<p>进入 image 文件夹，新建一个格式为【Repeat_Concept】，Repeat 的意义是重复学习训练集图片的次数，二次元图片选择 5-10 即可，三次元图片细节较为复杂可以选择设置在 10-30 之间，Concept 代表概念，训练对象的主要概念名称，最好是你设置的提示词就好了，同时，如果你想训练的 lora 有多个概念，可以选择新建多个不同的文件夹植入不同概念。比如：6_NingGuang，格式将裁切并且打标完成的图片即其标签拖到</p>\n</li>\n<li>\n<p>填写相关信息到 kohya_ss 内，注意 image folder 需要是你的 image 文件夹的路径而不是其下面的概念文件夹路径。</p>\n<p><img src=\"https://oss.kinda.info/image/202403061425301.png\" alt=\"\"></p>\n</li>\n</ol>\n<h3><strong>开始训练</strong></h3>\n<h2><strong>参数选择</strong></h2>\n<h3><strong>Source Model</strong></h3>\n<p><img src=\"https://oss.kinda.info/image/202403061428677.png\" alt=\"\"></p>\n<p>此处最好选择 custom，然后自行填入本地的模型，否则 sd 会自动下载对应基底模型，速度相对而言会很慢。</p>\n<p>作为模型训练的基底模型，一般会选择如下三种之一。</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<table><thead><tr><th></th><th><strong>SD 1.4/1.5</strong></th><th><strong>SDXL 0.9/1.0</strong></th><th><strong>SD 2.0/2.1</strong></th></tr></thead><tbody><tr><td>原始训练集尺寸</td><td>512*512</td><td>768*768</td><td>1024*1024</td></tr><tr><td>原始绘制精度/图像质量</td><td>很一般</td><td>较佳</td><td>非常强</td></tr><tr><td>训练需求</td><td>低</td><td>较高</td><td>非常高</td></tr><tr><td>流传广度/模型市场占比</td><td>高</td><td>低</td><td>中</td></tr></tbody></table>\n<p>💡 不同的基地模型一些底层构造不同，因此选择特定版本的底模时必须结合相应版本的 models 使用，否则的话会报错。</p>\n<p>如果是训练动漫人物的话，那么可以选择使用这个模型作为底模，这是 novalai 的初版泄漏模型。</p>\n<p><a href=\"https://huggingface.co/deepghs/animefull-latest-ckpt/tree/main\">deepghs/animefull-latest-ckpt at main</a></p>\n<p>但是 novalai 的模型已经很老了，所以也可以选择 AnyThing 等较新的模型，如下所示。</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<table><thead><tr><th></th><th><strong>真实系风格图像</strong></th><th><strong>二次元风格图像</strong></th></tr></thead><tbody><tr><td>始祖级模型</td><td>Stable Diffusion 1.5</td><td>Anime-full (NAI 模型)</td></tr><tr><td>风格中立的融合模型</td><td>ChillOut MixRealistic VisionMajicMix Realistic…</td><td>AnyLoRAAnything V3/V5ReV Animated…</td></tr></tbody></table>\n<p>Stable Diffusion 和 Novel AI Leaks 模型的对比如下所示。</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<table><thead><tr><th></th><th><strong>Stable Diffusion SD 原版模型系列</strong></th><th><strong>Novel AI Leaks Novel AI 泄露模型</strong></th></tr></thead><tbody><tr><td>原始/微调训练标注类型</td><td>（原始）自然语言</td><td>（微调）Danbooru Tag</td></tr><tr><td>原始/微调训练图片类型</td><td>（原始）大部分为真实照片（即部分绘画艺术作品）</td><td>（微调）二次元动漫风格图片</td></tr><tr><td>衍生</td><td>大量真实系大模型可以使用自然语言，也可以使用 Tag</td><td>大量二次元大模型使用 Tag 出图效果更好</td></tr></tbody></table>\n<h3><strong>Lora type</strong></h3>\n<p>不同的 lora 类型分别具有如下特征，可根据需要决定。其实一般情况下 IA3 就很合适了。</p>\n<p><img src=\"https://oss.kinda.info/image/202403061436918.png\" alt=\"\"></p>\n<h3><strong>Train Batch Size</strong></h3>\n<p>一次训练几张图片</p>\n<p>数值越大，由于总的图片数目固定，相对的总的需要训练的步数也就越少，但同时对显存的占用也就更高了，需要注意电脑的相关配置，如果显存在 10 个 G 一下的话建议保持 1 就好。</p>\n<h3><strong>Epoch</strong></h3>\n<p>一个 epoch 就是对整个训练数据集的一次完整遍历。epoch 的迭代次数影响着模型的训练效果，过少的 epoch 可能导致模型未能充分学习，而过多的 epoch 可能导致过拟合。</p>\n<h3><strong>Max train steps</strong></h3>\n<p>最大的训练步数，不管总步数你设置的是多少步，此处都会做拦截，即训练部署到这个数值的时候会自动停止。</p>\n<h3><strong>Save every N epochs</strong></h3>\n<p>每隔几次遍历生成一个 lora 模型。</p>\n<h3><strong>Learning Rate</strong></h3>\n<p>学习率，对于比较复杂的对象可以调整的大一些，对于比较简单的对象一定要调整的小一些。学习率过大可能导致过拟合，而过小可能导致欠拟合。一般情况下，参数设计合理的时候，学习率调整的比较大则可以适当降低训练步数，但也可能会导致跳过最优解。</p>\n<h3><strong>Optimizer</strong></h3>\n<p>优化器，一般情况下选择默认的 AdamW8bit 即可，选择 Prodigy（神童）则会自动更新各项学习率，即你只需要把所有的学习率均设置为 1 即可。</p>\n<p>⚠️ 注意，如果是 macbook 系列，这里不能使用 AdamW8bit，需要选择不依赖 cuda 的优化器比如 AdamW。</p>\n<h3><strong>Enable buckets</strong></h3>\n<p>应用分辨率桶，开启这一项后可以不需要对图片做固定尺寸裁剪，多数情况下默认开启。但是太多的桶会影响训练结果，所以尽可能的保持训练图片尺寸一致。</p>\n<h3><strong>LR Scheduler</strong></h3>\n<p>学习率调度器，这一项一般默认即可，如果设置为 cosine_with_restarts 则会一定程度上可以避免局部最优解的问题，在设置成 cosine_with_restarts 的同时记得设置下面的 LR number of cycles，这样才能够令这一参数生效，一般 LR number of cycles 设置为 3-5 即可，如果训练对象比较复杂可以适当增大。</p>\n<h3><strong>Network Rank (Dimension)</strong></h3>\n<p>💡 lora 模型的网络情况参数 1</p>\n<p>对应的是从原始矩阵中抽出来的行列，会直接影响模型大小（正比）。图形越是复杂，这一项可以考虑 64/128，因为学习到的特征项也就越多了。图形如果比较简单的话，一般使用 32/16/8 即可。二次元图形一般使用 16 即可，三次元才会考虑 64 即以上。对了，这一项很吃显存，如果显存比较低的情况下建议值低点就好。</p>\n<h3><strong>Network Alpha</strong></h3>\n<p>💡 lora 模型的网络情况参数 2</p>\n<p>对应的是最终生成的 lora 对基地模型的影响程度，值越接近于 Network Rank 则 lora 对基底模型的影响就越小，值越接近于 0 则对基地模型的微调影响越大，一般情况下采取 Rank 的一半即可。</p>\n<p><strong>网络模型的参数参考</strong></p>\n<p>💡 如果是训练三次元图片，那么考虑翻倍。</p>\n<p><img src=\"https://oss.kinda.info/image/202403061450500.png\" alt=\"\"></p>\n<h3><strong>Mixed precision &#x26; Save precision</strong></h3>\n<p>计算精度和保存的精度，实测 mac m1pro 芯片此处使用 fp16 似乎会导致报错，可以将其修改为 no 或者在启动 webui 脚本的时候加上  <code>—no-half</code> 命令。</p>\n<h3><strong>Cache latents</strong></h3>\n<p>缓存图片图片向量空间，这一项会在开始训练之前先把所有图片的向量空间缓存，在训练的过程中只需要反复读取即可，否则的话则需要一张一张的读取，开启之后会大幅增加训练速度。</p>\n<h3><strong>Cache latents to disk</strong></h3>\n<p>缓存图片图片向量空间到磁盘，这一项会保存图片向量空间到硬盘，在多次使用同一批次图片训练时能够起到优化训练速度的作用（即减去了初次图片向量读条的时间），但实测下来会对实际的训练时间有一定增加影响，可能是因为硬盘读取时间的问题。</p>\n<h3><strong>CrossAttention</strong></h3>\n<p>交叉注意力，如果你是 n 卡强烈建议开启，可以提高模型训练效率，能够降低显存需求并且显著提高训练速度，但注意 mac 用户暂不支持这一项，开启会导致报错。</p>\n<h3><strong>Memory efficient attention</strong></h3>\n<p>能够一定程度上压缩显存使用，低配用户可以选择开启，效果不如 xformers 好，且对训练速度影响较大，一般不建议开启。</p>\n<h3><strong>LR warmup</strong></h3>\n<p>开启这一项会使得在开始训练的时候保持一个比较高的学习率，能够让模型高效的被训练，一般建议一定程度上开启，10%就不错了。</p>\n<h3><strong>Sample every n steps</strong></h3>\n<p>每隔多少步生成一个预览，便于直观的看模型当前训练的效果如何。</p>\n<h2><strong>拟合情况总结</strong></h2>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<table><thead><tr><th><strong>过拟合怎么办</strong></th><th><strong>欠拟合怎么办</strong></th></tr></thead><tbody><tr><td>适当降低学习率</td><td>适当提高学习率</td></tr><tr><td>缩短学习步长</td><td>延长学习步长</td></tr><tr><td>降低<a href=\"https://www.notion.so/6c8f2445c20444a3a960804d7dab31d0?pvs=21\">https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21，提高 https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21(opens in a new tab)</a></td><td>提高<a href=\"https://www.notion.so/6c8f2445c20444a3a960804d7dab31d0?pvs=21\">https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21，降低 https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21(opens in a new tab)</a></td></tr><tr><td>减小<a href=\"https://www.notion.so/6c8f2445c20444a3a960804d7dab31d0?pvs=21\">https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21 数值(opens in a new tab)</a></td><td>增大<a href=\"https://www.notion.so/6c8f2445c20444a3a960804d7dab31d0?pvs=21\">https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21 数值(opens in a new tab)</a></td></tr><tr><td>使用正则化训练</td><td></td></tr></tbody></table>\n<p>💡 其他尝试也可以是更换 LoRA 类型，尝试另一种优化器/调度器，对训练集作调整，……</p>",
    "code": "const{Fragment:n,jsx:e,jsxs:i}=arguments[0];function _createMdxContent(r){const d={a:\"a\",code:\"code\",h2:\"h2\",h3:\"h3\",img:\"img\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",strong:\"strong\",table:\"table\",tbody:\"tbody\",td:\"td\",th:\"th\",thead:\"thead\",tr:\"tr\",...r.components};return i(n,{children:[e(d.p,{children:\"注意，本文档只针对 m 系列芯片的 macbook 用户。\"}),\"\\n\",e(d.h2,{children:e(d.strong,{children:\"快速开始\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"下载 kohya 仓库\"})}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-bash\",children:\"git clone git@github.com:bmaltais/kohya_ss.git\\n\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"启动 kohya\"})}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-bash\",children:\"cd kohya_ss./gui.sh\\n\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"图像裁剪\"})}),\"\\n\",e(d.p,{children:\"webui 自带裁剪功能，具体如下\"}),\"\\n\",e(d.p,{children:e(d.img,{src:\"https://oss.kinda.info/image/202403060009884.png\",alt:\"\"})}),\"\\n\",e(d.p,{children:\"webui 默认的人像焦点裁剪有时候并不是那么可靠，需要在完成之后检查一遍。如果人物比较瘦长的情况下的的话还可能导致人物被裁剪，这种情况建议手动裁切或者扩充边沿。\"}),\"\\n\",e(d.p,{children:\"💡 裁剪结果也不一定要选择 512*512，因为 sd 在训练的时候会预先根据不同图片大小进行分桶。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"打标\"})}),\"\\n\",i(d.p,{children:[\"下面这个仓库是公认的比较合适的打标仓库（似乎对于二次元风格更合适一些，应该是因为都是基于标签制的，并且标签来自于\",e(d.a,{href:\"https://safebooru.org/\",children:\"https://safebooru.org\"}),\"这一网站经训练生成的）。\"]}),\"\\n\",e(d.p,{children:e(d.a,{href:\"https://github.com/picobyte/stable-diffusion-webui-wd14-tagger\",children:\"https://github.com/picobyte/stable-diffusion-webui-wd14-tagger\"})}),\"\\n\",e(d.p,{children:\"把项目克隆到 sd 的 extensions 目录下，然后重启 sd 即可。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-bash\",children:\"cd ./extensionsgit clone git@github.com:picobyte/stable-diffusion-webui-wd14-tagger.git\\n\"})}),\"\\n\",e(d.p,{children:e(d.img,{src:\"https://oss.kinda.info/image/202403061424310.png\",alt:\"\"})}),\"\\n\",e(d.p,{children:\"注意下面的 Additional tags，这里你需要填入这个 lora 的触发词语，在最终打标完成的 txt 文件中这个触发词语会被加入并且置于 prompts 的第一个。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"设置训练参数\"})}),\"\\n\",i(d.p,{children:[\"详见\",e(d.a,{href:\"https://human-ai.site/image/lora#%E5%8F%82%E6%95%B0%E9%80%89%E6%8B%A9\",children:\"参数选择\"})]}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"选底模\"})}),\"\\n\",i(d.p,{children:[\"详见\",e(d.a,{href:\"https://human-ai.site/image/lora#%E5%8F%82%E6%95%B0%E9%80%89%E6%8B%A9\",children:\"参数选择\"})]}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"建立训练文件夹（注意：文件夹的相关路径不要有中文和空格）\"})}),\"\\n\",i(d.ol,{children:[\"\\n\",i(d.li,{children:[\"\\n\",e(d.p,{children:\"建立一个文件夹，命名为你的训练项目名字。比如 NingGuang。\"}),\"\\n\"]}),\"\\n\",i(d.li,{children:[\"\\n\",e(d.p,{children:\"在 NingGuang 目录下新建三个文件夹，分别命名为 image、log、models。\"}),\"\\n\"]}),\"\\n\",i(d.li,{children:[\"\\n\",e(d.p,{children:\"进入 image 文件夹，新建一个格式为【Repeat_Concept】，Repeat 的意义是重复学习训练集图片的次数，二次元图片选择 5-10 即可，三次元图片细节较为复杂可以选择设置在 10-30 之间，Concept 代表概念，训练对象的主要概念名称，最好是你设置的提示词就好了，同时，如果你想训练的 lora 有多个概念，可以选择新建多个不同的文件夹植入不同概念。比如：6_NingGuang，格式将裁切并且打标完成的图片即其标签拖到\"}),\"\\n\"]}),\"\\n\",i(d.li,{children:[\"\\n\",e(d.p,{children:\"填写相关信息到 kohya_ss 内，注意 image folder 需要是你的 image 文件夹的路径而不是其下面的概念文件夹路径。\"}),\"\\n\",e(d.p,{children:e(d.img,{src:\"https://oss.kinda.info/image/202403061425301.png\",alt:\"\"})}),\"\\n\"]}),\"\\n\"]}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"开始训练\"})}),\"\\n\",e(d.h2,{children:e(d.strong,{children:\"参数选择\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Source Model\"})}),\"\\n\",e(d.p,{children:e(d.img,{src:\"https://oss.kinda.info/image/202403061428677.png\",alt:\"\"})}),\"\\n\",e(d.p,{children:\"此处最好选择 custom，然后自行填入本地的模型，否则 sd 会自动下载对应基底模型，速度相对而言会很慢。\"}),\"\\n\",e(d.p,{children:\"作为模型训练的基底模型，一般会选择如下三种之一。\"}),\"\\n\",i(d.table,{children:[e(d.thead,{children:i(d.tr,{children:[e(d.th,{}),e(d.th,{children:e(d.strong,{children:\"SD 1.4/1.5\"})}),e(d.th,{children:e(d.strong,{children:\"SDXL 0.9/1.0\"})}),e(d.th,{children:e(d.strong,{children:\"SD 2.0/2.1\"})})]})}),i(d.tbody,{children:[i(d.tr,{children:[e(d.td,{children:\"原始训练集尺寸\"}),e(d.td,{children:\"512*512\"}),e(d.td,{children:\"768*768\"}),e(d.td,{children:\"1024*1024\"})]}),i(d.tr,{children:[e(d.td,{children:\"原始绘制精度/图像质量\"}),e(d.td,{children:\"很一般\"}),e(d.td,{children:\"较佳\"}),e(d.td,{children:\"非常强\"})]}),i(d.tr,{children:[e(d.td,{children:\"训练需求\"}),e(d.td,{children:\"低\"}),e(d.td,{children:\"较高\"}),e(d.td,{children:\"非常高\"})]}),i(d.tr,{children:[e(d.td,{children:\"流传广度/模型市场占比\"}),e(d.td,{children:\"高\"}),e(d.td,{children:\"低\"}),e(d.td,{children:\"中\"})]})]})]}),\"\\n\",e(d.p,{children:\"💡 不同的基地模型一些底层构造不同，因此选择特定版本的底模时必须结合相应版本的 models 使用，否则的话会报错。\"}),\"\\n\",e(d.p,{children:\"如果是训练动漫人物的话，那么可以选择使用这个模型作为底模，这是 novalai 的初版泄漏模型。\"}),\"\\n\",e(d.p,{children:e(d.a,{href:\"https://huggingface.co/deepghs/animefull-latest-ckpt/tree/main\",children:\"deepghs/animefull-latest-ckpt at main\"})}),\"\\n\",e(d.p,{children:\"但是 novalai 的模型已经很老了，所以也可以选择 AnyThing 等较新的模型，如下所示。\"}),\"\\n\",i(d.table,{children:[e(d.thead,{children:i(d.tr,{children:[e(d.th,{}),e(d.th,{children:e(d.strong,{children:\"真实系风格图像\"})}),e(d.th,{children:e(d.strong,{children:\"二次元风格图像\"})})]})}),i(d.tbody,{children:[i(d.tr,{children:[e(d.td,{children:\"始祖级模型\"}),e(d.td,{children:\"Stable Diffusion 1.5\"}),e(d.td,{children:\"Anime-full (NAI 模型)\"})]}),i(d.tr,{children:[e(d.td,{children:\"风格中立的融合模型\"}),e(d.td,{children:\"ChillOut MixRealistic VisionMajicMix Realistic…\"}),e(d.td,{children:\"AnyLoRAAnything V3/V5ReV Animated…\"})]})]})]}),\"\\n\",e(d.p,{children:\"Stable Diffusion 和 Novel AI Leaks 模型的对比如下所示。\"}),\"\\n\",i(d.table,{children:[e(d.thead,{children:i(d.tr,{children:[e(d.th,{}),e(d.th,{children:e(d.strong,{children:\"Stable Diffusion SD 原版模型系列\"})}),e(d.th,{children:e(d.strong,{children:\"Novel AI Leaks Novel AI 泄露模型\"})})]})}),i(d.tbody,{children:[i(d.tr,{children:[e(d.td,{children:\"原始/微调训练标注类型\"}),e(d.td,{children:\"（原始）自然语言\"}),e(d.td,{children:\"（微调）Danbooru Tag\"})]}),i(d.tr,{children:[e(d.td,{children:\"原始/微调训练图片类型\"}),e(d.td,{children:\"（原始）大部分为真实照片（即部分绘画艺术作品）\"}),e(d.td,{children:\"（微调）二次元动漫风格图片\"})]}),i(d.tr,{children:[e(d.td,{children:\"衍生\"}),e(d.td,{children:\"大量真实系大模型可以使用自然语言，也可以使用 Tag\"}),e(d.td,{children:\"大量二次元大模型使用 Tag 出图效果更好\"})]})]})]}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Lora type\"})}),\"\\n\",e(d.p,{children:\"不同的 lora 类型分别具有如下特征，可根据需要决定。其实一般情况下 IA3 就很合适了。\"}),\"\\n\",e(d.p,{children:e(d.img,{src:\"https://oss.kinda.info/image/202403061436918.png\",alt:\"\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Train Batch Size\"})}),\"\\n\",e(d.p,{children:\"一次训练几张图片\"}),\"\\n\",e(d.p,{children:\"数值越大，由于总的图片数目固定，相对的总的需要训练的步数也就越少，但同时对显存的占用也就更高了，需要注意电脑的相关配置，如果显存在 10 个 G 一下的话建议保持 1 就好。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Epoch\"})}),\"\\n\",e(d.p,{children:\"一个 epoch 就是对整个训练数据集的一次完整遍历。epoch 的迭代次数影响着模型的训练效果，过少的 epoch 可能导致模型未能充分学习，而过多的 epoch 可能导致过拟合。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Max train steps\"})}),\"\\n\",e(d.p,{children:\"最大的训练步数，不管总步数你设置的是多少步，此处都会做拦截，即训练部署到这个数值的时候会自动停止。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Save every N epochs\"})}),\"\\n\",e(d.p,{children:\"每隔几次遍历生成一个 lora 模型。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Learning Rate\"})}),\"\\n\",e(d.p,{children:\"学习率，对于比较复杂的对象可以调整的大一些，对于比较简单的对象一定要调整的小一些。学习率过大可能导致过拟合，而过小可能导致欠拟合。一般情况下，参数设计合理的时候，学习率调整的比较大则可以适当降低训练步数，但也可能会导致跳过最优解。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Optimizer\"})}),\"\\n\",e(d.p,{children:\"优化器，一般情况下选择默认的 AdamW8bit 即可，选择 Prodigy（神童）则会自动更新各项学习率，即你只需要把所有的学习率均设置为 1 即可。\"}),\"\\n\",e(d.p,{children:\"⚠️ 注意，如果是 macbook 系列，这里不能使用 AdamW8bit，需要选择不依赖 cuda 的优化器比如 AdamW。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Enable buckets\"})}),\"\\n\",e(d.p,{children:\"应用分辨率桶，开启这一项后可以不需要对图片做固定尺寸裁剪，多数情况下默认开启。但是太多的桶会影响训练结果，所以尽可能的保持训练图片尺寸一致。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"LR Scheduler\"})}),\"\\n\",e(d.p,{children:\"学习率调度器，这一项一般默认即可，如果设置为 cosine_with_restarts 则会一定程度上可以避免局部最优解的问题，在设置成 cosine_with_restarts 的同时记得设置下面的 LR number of cycles，这样才能够令这一参数生效，一般 LR number of cycles 设置为 3-5 即可，如果训练对象比较复杂可以适当增大。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Network Rank (Dimension)\"})}),\"\\n\",e(d.p,{children:\"💡 lora 模型的网络情况参数 1\"}),\"\\n\",e(d.p,{children:\"对应的是从原始矩阵中抽出来的行列，会直接影响模型大小（正比）。图形越是复杂，这一项可以考虑 64/128，因为学习到的特征项也就越多了。图形如果比较简单的话，一般使用 32/16/8 即可。二次元图形一般使用 16 即可，三次元才会考虑 64 即以上。对了，这一项很吃显存，如果显存比较低的情况下建议值低点就好。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Network Alpha\"})}),\"\\n\",e(d.p,{children:\"💡 lora 模型的网络情况参数 2\"}),\"\\n\",e(d.p,{children:\"对应的是最终生成的 lora 对基地模型的影响程度，值越接近于 Network Rank 则 lora 对基底模型的影响就越小，值越接近于 0 则对基地模型的微调影响越大，一般情况下采取 Rank 的一半即可。\"}),\"\\n\",e(d.p,{children:e(d.strong,{children:\"网络模型的参数参考\"})}),\"\\n\",e(d.p,{children:\"💡 如果是训练三次元图片，那么考虑翻倍。\"}),\"\\n\",e(d.p,{children:e(d.img,{src:\"https://oss.kinda.info/image/202403061450500.png\",alt:\"\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Mixed precision & Save precision\"})}),\"\\n\",i(d.p,{children:[\"计算精度和保存的精度，实测 mac m1pro 芯片此处使用 fp16 似乎会导致报错，可以将其修改为 no 或者在启动 webui 脚本的时候加上  \",e(d.code,{children:\"—no-half\"}),\" 命令。\"]}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Cache latents\"})}),\"\\n\",e(d.p,{children:\"缓存图片图片向量空间，这一项会在开始训练之前先把所有图片的向量空间缓存，在训练的过程中只需要反复读取即可，否则的话则需要一张一张的读取，开启之后会大幅增加训练速度。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Cache latents to disk\"})}),\"\\n\",e(d.p,{children:\"缓存图片图片向量空间到磁盘，这一项会保存图片向量空间到硬盘，在多次使用同一批次图片训练时能够起到优化训练速度的作用（即减去了初次图片向量读条的时间），但实测下来会对实际的训练时间有一定增加影响，可能是因为硬盘读取时间的问题。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"CrossAttention\"})}),\"\\n\",e(d.p,{children:\"交叉注意力，如果你是 n 卡强烈建议开启，可以提高模型训练效率，能够降低显存需求并且显著提高训练速度，但注意 mac 用户暂不支持这一项，开启会导致报错。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Memory efficient attention\"})}),\"\\n\",e(d.p,{children:\"能够一定程度上压缩显存使用，低配用户可以选择开启，效果不如 xformers 好，且对训练速度影响较大，一般不建议开启。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"LR warmup\"})}),\"\\n\",e(d.p,{children:\"开启这一项会使得在开始训练的时候保持一个比较高的学习率，能够让模型高效的被训练，一般建议一定程度上开启，10%就不错了。\"}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"Sample every n steps\"})}),\"\\n\",e(d.p,{children:\"每隔多少步生成一个预览，便于直观的看模型当前训练的效果如何。\"}),\"\\n\",e(d.h2,{children:e(d.strong,{children:\"拟合情况总结\"})}),\"\\n\",i(d.table,{children:[e(d.thead,{children:i(d.tr,{children:[e(d.th,{children:e(d.strong,{children:\"过拟合怎么办\"})}),e(d.th,{children:e(d.strong,{children:\"欠拟合怎么办\"})})]})}),i(d.tbody,{children:[i(d.tr,{children:[e(d.td,{children:\"适当降低学习率\"}),e(d.td,{children:\"适当提高学习率\"})]}),i(d.tr,{children:[e(d.td,{children:\"缩短学习步长\"}),e(d.td,{children:\"延长学习步长\"})]}),i(d.tr,{children:[i(d.td,{children:[\"降低\",e(d.a,{href:\"https://www.notion.so/6c8f2445c20444a3a960804d7dab31d0?pvs=21\",children:\"https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21，提高 https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21(opens in a new tab)\"})]}),i(d.td,{children:[\"提高\",e(d.a,{href:\"https://www.notion.so/6c8f2445c20444a3a960804d7dab31d0?pvs=21\",children:\"https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21，降低 https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21(opens in a new tab)\"})]})]}),i(d.tr,{children:[i(d.td,{children:[\"减小\",e(d.a,{href:\"https://www.notion.so/6c8f2445c20444a3a960804d7dab31d0?pvs=21\",children:\"https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21 数值(opens in a new tab)\"})]}),i(d.td,{children:[\"增大\",e(d.a,{href:\"https://www.notion.so/6c8f2445c20444a3a960804d7dab31d0?pvs=21\",children:\"https://www.notion.so/AI-6c8f2445c20444a3a960804d7dab31d0?pvs=21 数值(opens in a new tab)\"})]})]}),i(d.tr,{children:[e(d.td,{children:\"使用正则化训练\"}),e(d.td,{})]})]})]}),\"\\n\",e(d.p,{children:\"💡 其他尝试也可以是更换 LoRA 类型，尝试另一种优化器/调度器，对训练集作调整，……\"})]})}return{default:function(n={}){const{wrapper:i}=n.components||{};return i?e(i,{...n,children:e(_createMdxContent,{...n})}):_createMdxContent(n)}};",
    "permalink": "/posts/lora"
  },
  {
    "title": "neo4j",
    "slug": "posts/neo4j",
    "lastModified": "2025-05-07T08:10:16.000Z",
    "tags": [
      "database",
      "graph"
    ],
    "metadata": {
      "readingTime": 4,
      "wordCount": 979.6400000000001
    },
    "excerpt": "介绍\nNeo4j 是一个图形数据库，它使用图形结构来存储数据。数据通过节点（nodes）、关系（relationships）和属性（properties）来表示。Python 中可以通过 neo4j 驱动来与 Neo4j 数据库进行交互，本教程将向你展示如何在 Python 中使用 Neo4j 驱动进行基础操作。\n1. 安装和配置\n安装 Neo4j Python 驱动\n首先，确保你已经安装了 Neo4j 数据库，并且已经运行它。然后，你需要安装 Neo4j 的 Python 驱动。\npip install neo4",
    "content": "<h2>介绍</h2>\n<p>Neo4j 是一个图形数据库，它使用图形结构来存储数据。数据通过节点（nodes）、关系（relationships）和属性（properties）来表示。Python 中可以通过 <strong>neo4j</strong> 驱动来与 Neo4j 数据库进行交互，本教程将向你展示如何在 Python 中使用 Neo4j 驱动进行基础操作。</p>\n<h2><strong>1. 安装和配置</strong></h2>\n<h3><strong>安装 Neo4j Python 驱动</strong></h3>\n<p>首先，确保你已经安装了 Neo4j 数据库，并且已经运行它。然后，你需要安装 Neo4j 的 Python 驱动。</p>\n<pre><code class=\"language-shell\">pip install neo4j\n</code></pre>\n<h3><strong>连接到 Neo4j 数据库</strong></h3>\n<p>连接到 Neo4j 数据库需要提供数据库的 URI、用户名和密码。通常使用 bolt 协议来连接 Neo4j，默认端口为 7687。</p>\n<pre><code class=\"language-python\">from neo4j import GraphDatabase\n\n# 创建 Neo4j 驱动实例\nuri = \"bolt://localhost:7687\"  # Neo4j URI\nusername = \"neo4j\"  # Neo4j 默认用户名\npassword = \"your_password\"  # 密码\ndriver = GraphDatabase.driver(uri, auth=(username, password))\n</code></pre>\n<h2><strong>2. 节点的基础操作</strong></h2>\n<h3><strong>创建节点</strong></h3>\n<p>节点是图数据库的基本元素之一，你可以通过 Cypher 查询语言创建节点，并为其设置属性。</p>\n<pre><code class=\"language-python\">def create_node(tx, node_id, label):\n    query = \"CREATE (n:Animal {custom_id: $node_id, label: $label})\"\n    tx.run(query, node_id=node_id, label=label)\n\n# 执行创建节点\nwith driver.session() as session:\n    session.write_transaction(create_node, \"unique_id_1\", \"Mammal\")\n    print(\"Node created.\")\n\n# 关闭驱动\ndriver.close()\n</code></pre>\n<h3><strong>查询节点</strong></h3>\n<p>你可以使用 MATCH 查询来查找符合条件的节点。</p>\n<pre><code class=\"language-python\">def get_node(tx, node_id):\n    query = \"MATCH (n:Animal {custom_id: $node_id}) RETURN n\"\n    result = tx.run(query, node_id=node_id)\n    for record in result:\n        print(record[\"n\"])\n\n# 执行查询\nwith driver.session() as session:\n    session.read_transaction(get_node, \"unique_id_1\")\n</code></pre>\n<h3><strong>更新节点</strong></h3>\n<p>更新节点的属性时，可以使用 SET 语句。</p>\n<pre><code class=\"language-python\">def update_node(tx, node_id, new_label):\n    query = \"MATCH (n:Animal {custom_id: $node_id}) SET n.label = $new_label\"\n    tx.run(query, node_id=node_id, new_label=new_label)\n\n# 执行更新\nwith driver.session() as session:\n    session.write_transaction(update_node, \"unique_id_1\", \"Dog\")\n</code></pre>\n<h3><strong>删除节点</strong></h3>\n<p>删除节点时，需要使用 DETACH DELETE，确保删除该节点及其所有关系。</p>\n<pre><code class=\"language-python\">def delete_node(tx, node_id):\n    query = \"MATCH (n:Animal {custom_id: $node_id}) DETACH DELETE n\"\n    tx.run(query, node_id=node_id)\n\n# 执行删除\nwith driver.session() as session:\n    session.write_transaction(delete_node, \"unique_id_1\")\n    print(\"Node deleted.\")\n</code></pre>\n<h2><strong>3. 关系的基础操作</strong></h2>\n<h3><strong>创建关系</strong></h3>\n<p>创建关系时，你需要指定关系的类型，并连接两个节点。</p>\n<pre><code class=\"language-python\">def create_relationship(tx, node1_id, node2_id):\n    query = \"\"\"\n    MATCH (a:Animal {custom_id: $node1_id}), (b:Animal {custom_id: $node2_id})\n    CREATE (a)-[:KNOWS]->(b)\n    \"\"\"\n    tx.run(query, node1_id=node1_id, node2_id=node2_id)\n\n# 执行创建关系\nwith driver.session() as session:\n    session.write_transaction(create_relationship, \"unique_id_1\", \"unique_id_2\")\n</code></pre>\n<h3><strong>查询关系</strong></h3>\n<p>你可以使用 MATCH 查找关系，并指定起始和结束节点。</p>\n<pre><code class=\"language-python\">def get_relationship(tx, node1_id, node2_id):\n    query = \"\"\"\n    MATCH (a)-[r:KNOWS]->(b)\n    WHERE a.custom_id = $node1_id AND b.custom_id = $node2_id\n    RETURN r\n    \"\"\"\n    result = tx.run(query, node1_id=node1_id, node2_id=node2_id)\n    for record in result:\n        print(record[\"r\"])\n\n# 执行查询\nwith driver.session() as session:\n    session.read_transaction(get_relationship, \"unique_id_1\", \"unique_id_2\")\n</code></pre>\n<h3><strong>删除关系</strong></h3>\n<p>删除节点之间的关系时，可以使用 DELETE。</p>\n<pre><code class=\"language-python\">def delete_relationship(tx, node1_id, node2_id):\n    query = \"\"\"\n    MATCH (a)-[r]->(b)\n    WHERE a.custom_id = $node1_id AND b.custom_id = $node2_id\n    DELETE r\n    \"\"\"\n    tx.run(query, node1_id=node1_id, node2_id=node2_id)\n\n# 执行删除关系\nwith driver.session() as session:\n    session.write_transaction(delete_relationship, \"unique_id_1\", \"unique_id_2\")\n    print(\"Relationship deleted.\")\n</code></pre>\n<h2><strong>4. 创建约束和索引</strong></h2>\n<h3><strong>创建唯一约束</strong></h3>\n<p>唯一约束确保某个属性在数据库中是唯一的。</p>\n<pre><code class=\"language-python\">def create_unique_constraint(tx):\n    query = \"CREATE CONSTRAINT IF NOT EXISTS ON (n:Animal) ASSERT n.custom_id IS UNIQUE\"\n    tx.run(query)\n\n# 执行创建唯一约束\nwith driver.session() as session:\n    session.write_transaction(create_unique_constraint)\n    print(\"Unique constraint created.\")\n</code></pre>\n<h3><strong>创建存在性约束</strong></h3>\n<p>存在性约束确保节点或关系必须包含某个属性。</p>\n<pre><code class=\"language-python\">def create_existence_constraint(tx):\n    query = \"CREATE CONSTRAINT IF NOT EXISTS ON (n:Animal) ASSERT exists(n.custom_id)\"\n    tx.run(query)\n\n# 执行创建存在性约束\nwith driver.session() as session:\n    session.write_transaction(create_existence_constraint)\n    print(\"Existence constraint created.\")\n</code></pre>\n<h3><strong>创建索引</strong></h3>\n<p>索引用于提高某个属性的查询性能。</p>\n<pre><code class=\"language-python\">def create_index(tx):\n    query = \"CREATE INDEX IF NOT EXISTS FOR (n:Animal) ON (n.custom_id)\"\n    tx.run(query)\n\n# 执行创建索引\nwith driver.session() as session:\n    session.write_transaction(create_index)\n    print(\"Index created.\")\n</code></pre>\n<h2><strong>5. 复杂查询和聚合操作</strong></h2>\n<h3><strong>聚合查询</strong></h3>\n<p>Neo4j 支持多种聚合函数，比如 COUNT、SUM、AVG 等。可以用来统计节点或关系的数量。</p>\n<pre><code class=\"language-python\">def count_nodes(tx):\n    query = \"MATCH (n:Animal) RETURN COUNT(n)\"\n    result = tx.run(query)\n    for record in result:\n        print(record[\"COUNT(n)\"])\n\n# 执行聚合查询\nwith driver.session() as session:\n    session.read_transaction(count_nodes)\n</code></pre>\n<h3><strong>查询带条件的关系</strong></h3>\n<p>你可以使用条件来过滤查询结果。</p>\n<pre><code class=\"language-python\">def filter_nodes(tx):\n    query = \"MATCH (n:Animal) WHERE n.label = 'Dog' RETURN n\"\n    result = tx.run(query)\n    for record in result:\n        print(record[\"n\"])\n\n# 执行条件查询\nwith driver.session() as session:\n    session.read_transaction(filter_nodes)\n</code></pre>\n<h2><strong>6. 批量操作</strong></h2>\n<h3><strong>批量创建节点</strong></h3>\n<pre><code class=\"language-python\">def create_multiple_nodes(tx, nodes):\n    query = \"UNWIND $nodes AS node CREATE (n:Animal {custom_id: node.custom_id, label: node.label})\"\n    tx.run(query, nodes=nodes)\n\n# 执行批量创建\nnodes = [\n    {\"custom_id\": \"unique_id_1\", \"label\": \"Dog\"},\n    {\"custom_id\": \"unique_id_2\", \"label\": \"Cat\"},\n    {\"custom_id\": \"unique_id_3\", \"label\": \"Fox\"}\n]\nwith driver.session() as session:\n    session.write_transaction(create_multiple_nodes, nodes)\n</code></pre>\n<h2><strong>7. 关闭连接</strong></h2>\n<p>完成操作后，关闭连接：</p>\n<pre><code class=\"language-python\"># 关闭驱动\ndriver.close()\n</code></pre>",
    "code": "const{Fragment:n,jsx:e,jsxs:i}=arguments[0];function _createMdxContent(r){const d={code:\"code\",h2:\"h2\",h3:\"h3\",p:\"p\",pre:\"pre\",strong:\"strong\",...r.components};return i(n,{children:[e(d.h2,{children:\"介绍\"}),\"\\n\",i(d.p,{children:[\"Neo4j 是一个图形数据库，它使用图形结构来存储数据。数据通过节点（nodes）、关系（relationships）和属性（properties）来表示。Python 中可以通过 \",e(d.strong,{children:\"neo4j\"}),\" 驱动来与 Neo4j 数据库进行交互，本教程将向你展示如何在 Python 中使用 Neo4j 驱动进行基础操作。\"]}),\"\\n\",e(d.h2,{children:e(d.strong,{children:\"1. 安装和配置\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"安装 Neo4j Python 驱动\"})}),\"\\n\",e(d.p,{children:\"首先，确保你已经安装了 Neo4j 数据库，并且已经运行它。然后，你需要安装 Neo4j 的 Python 驱动。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-shell\",children:\"pip install neo4j\\n\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"连接到 Neo4j 数据库\"})}),\"\\n\",e(d.p,{children:\"连接到 Neo4j 数据库需要提供数据库的 URI、用户名和密码。通常使用 bolt 协议来连接 Neo4j，默认端口为 7687。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'from neo4j import GraphDatabase\\n\\n# 创建 Neo4j 驱动实例\\nuri = \"bolt://localhost:7687\"  # Neo4j URI\\nusername = \"neo4j\"  # Neo4j 默认用户名\\npassword = \"your_password\"  # 密码\\ndriver = GraphDatabase.driver(uri, auth=(username, password))\\n'})}),\"\\n\",e(d.h2,{children:e(d.strong,{children:\"2. 节点的基础操作\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"创建节点\"})}),\"\\n\",e(d.p,{children:\"节点是图数据库的基本元素之一，你可以通过 Cypher 查询语言创建节点，并为其设置属性。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def create_node(tx, node_id, label):\\n    query = \"CREATE (n:Animal {custom_id: $node_id, label: $label})\"\\n    tx.run(query, node_id=node_id, label=label)\\n\\n# 执行创建节点\\nwith driver.session() as session:\\n    session.write_transaction(create_node, \"unique_id_1\", \"Mammal\")\\n    print(\"Node created.\")\\n\\n# 关闭驱动\\ndriver.close()\\n'})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"查询节点\"})}),\"\\n\",e(d.p,{children:\"你可以使用 MATCH 查询来查找符合条件的节点。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def get_node(tx, node_id):\\n    query = \"MATCH (n:Animal {custom_id: $node_id}) RETURN n\"\\n    result = tx.run(query, node_id=node_id)\\n    for record in result:\\n        print(record[\"n\"])\\n\\n# 执行查询\\nwith driver.session() as session:\\n    session.read_transaction(get_node, \"unique_id_1\")\\n'})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"更新节点\"})}),\"\\n\",e(d.p,{children:\"更新节点的属性时，可以使用 SET 语句。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def update_node(tx, node_id, new_label):\\n    query = \"MATCH (n:Animal {custom_id: $node_id}) SET n.label = $new_label\"\\n    tx.run(query, node_id=node_id, new_label=new_label)\\n\\n# 执行更新\\nwith driver.session() as session:\\n    session.write_transaction(update_node, \"unique_id_1\", \"Dog\")\\n'})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"删除节点\"})}),\"\\n\",e(d.p,{children:\"删除节点时，需要使用 DETACH DELETE，确保删除该节点及其所有关系。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def delete_node(tx, node_id):\\n    query = \"MATCH (n:Animal {custom_id: $node_id}) DETACH DELETE n\"\\n    tx.run(query, node_id=node_id)\\n\\n# 执行删除\\nwith driver.session() as session:\\n    session.write_transaction(delete_node, \"unique_id_1\")\\n    print(\"Node deleted.\")\\n'})}),\"\\n\",e(d.h2,{children:e(d.strong,{children:\"3. 关系的基础操作\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"创建关系\"})}),\"\\n\",e(d.p,{children:\"创建关系时，你需要指定关系的类型，并连接两个节点。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def create_relationship(tx, node1_id, node2_id):\\n    query = \"\"\"\\n    MATCH (a:Animal {custom_id: $node1_id}), (b:Animal {custom_id: $node2_id})\\n    CREATE (a)-[:KNOWS]->(b)\\n    \"\"\"\\n    tx.run(query, node1_id=node1_id, node2_id=node2_id)\\n\\n# 执行创建关系\\nwith driver.session() as session:\\n    session.write_transaction(create_relationship, \"unique_id_1\", \"unique_id_2\")\\n'})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"查询关系\"})}),\"\\n\",e(d.p,{children:\"你可以使用 MATCH 查找关系，并指定起始和结束节点。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def get_relationship(tx, node1_id, node2_id):\\n    query = \"\"\"\\n    MATCH (a)-[r:KNOWS]->(b)\\n    WHERE a.custom_id = $node1_id AND b.custom_id = $node2_id\\n    RETURN r\\n    \"\"\"\\n    result = tx.run(query, node1_id=node1_id, node2_id=node2_id)\\n    for record in result:\\n        print(record[\"r\"])\\n\\n# 执行查询\\nwith driver.session() as session:\\n    session.read_transaction(get_relationship, \"unique_id_1\", \"unique_id_2\")\\n'})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"删除关系\"})}),\"\\n\",e(d.p,{children:\"删除节点之间的关系时，可以使用 DELETE。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def delete_relationship(tx, node1_id, node2_id):\\n    query = \"\"\"\\n    MATCH (a)-[r]->(b)\\n    WHERE a.custom_id = $node1_id AND b.custom_id = $node2_id\\n    DELETE r\\n    \"\"\"\\n    tx.run(query, node1_id=node1_id, node2_id=node2_id)\\n\\n# 执行删除关系\\nwith driver.session() as session:\\n    session.write_transaction(delete_relationship, \"unique_id_1\", \"unique_id_2\")\\n    print(\"Relationship deleted.\")\\n'})}),\"\\n\",e(d.h2,{children:e(d.strong,{children:\"4. 创建约束和索引\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"创建唯一约束\"})}),\"\\n\",e(d.p,{children:\"唯一约束确保某个属性在数据库中是唯一的。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def create_unique_constraint(tx):\\n    query = \"CREATE CONSTRAINT IF NOT EXISTS ON (n:Animal) ASSERT n.custom_id IS UNIQUE\"\\n    tx.run(query)\\n\\n# 执行创建唯一约束\\nwith driver.session() as session:\\n    session.write_transaction(create_unique_constraint)\\n    print(\"Unique constraint created.\")\\n'})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"创建存在性约束\"})}),\"\\n\",e(d.p,{children:\"存在性约束确保节点或关系必须包含某个属性。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def create_existence_constraint(tx):\\n    query = \"CREATE CONSTRAINT IF NOT EXISTS ON (n:Animal) ASSERT exists(n.custom_id)\"\\n    tx.run(query)\\n\\n# 执行创建存在性约束\\nwith driver.session() as session:\\n    session.write_transaction(create_existence_constraint)\\n    print(\"Existence constraint created.\")\\n'})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"创建索引\"})}),\"\\n\",e(d.p,{children:\"索引用于提高某个属性的查询性能。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def create_index(tx):\\n    query = \"CREATE INDEX IF NOT EXISTS FOR (n:Animal) ON (n.custom_id)\"\\n    tx.run(query)\\n\\n# 执行创建索引\\nwith driver.session() as session:\\n    session.write_transaction(create_index)\\n    print(\"Index created.\")\\n'})}),\"\\n\",e(d.h2,{children:e(d.strong,{children:\"5. 复杂查询和聚合操作\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"聚合查询\"})}),\"\\n\",e(d.p,{children:\"Neo4j 支持多种聚合函数，比如 COUNT、SUM、AVG 等。可以用来统计节点或关系的数量。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def count_nodes(tx):\\n    query = \"MATCH (n:Animal) RETURN COUNT(n)\"\\n    result = tx.run(query)\\n    for record in result:\\n        print(record[\"COUNT(n)\"])\\n\\n# 执行聚合查询\\nwith driver.session() as session:\\n    session.read_transaction(count_nodes)\\n'})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"查询带条件的关系\"})}),\"\\n\",e(d.p,{children:\"你可以使用条件来过滤查询结果。\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def filter_nodes(tx):\\n    query = \"MATCH (n:Animal) WHERE n.label = \\'Dog\\' RETURN n\"\\n    result = tx.run(query)\\n    for record in result:\\n        print(record[\"n\"])\\n\\n# 执行条件查询\\nwith driver.session() as session:\\n    session.read_transaction(filter_nodes)\\n'})}),\"\\n\",e(d.h2,{children:e(d.strong,{children:\"6. 批量操作\"})}),\"\\n\",e(d.h3,{children:e(d.strong,{children:\"批量创建节点\"})}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:'def create_multiple_nodes(tx, nodes):\\n    query = \"UNWIND $nodes AS node CREATE (n:Animal {custom_id: node.custom_id, label: node.label})\"\\n    tx.run(query, nodes=nodes)\\n\\n# 执行批量创建\\nnodes = [\\n    {\"custom_id\": \"unique_id_1\", \"label\": \"Dog\"},\\n    {\"custom_id\": \"unique_id_2\", \"label\": \"Cat\"},\\n    {\"custom_id\": \"unique_id_3\", \"label\": \"Fox\"}\\n]\\nwith driver.session() as session:\\n    session.write_transaction(create_multiple_nodes, nodes)\\n'})}),\"\\n\",e(d.h2,{children:e(d.strong,{children:\"7. 关闭连接\"})}),\"\\n\",e(d.p,{children:\"完成操作后，关闭连接：\"}),\"\\n\",e(d.pre,{children:e(d.code,{className:\"language-python\",children:\"# 关闭驱动\\ndriver.close()\\n\"})})]})}return{default:function(n={}){const{wrapper:i}=n.components||{};return i?e(i,{...n,children:e(_createMdxContent,{...n})}):_createMdxContent(n)}};",
    "permalink": "/posts/neo4j"
  }
]